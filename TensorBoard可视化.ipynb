{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "TensorBoard可视化.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryan-Lily/python-learning-notes/blob/master/TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY8-a_p13SrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms as tfs\n",
        "from datetime import datetime\n",
        "\n",
        "from utils import resnet\n",
        "\n",
        "#使用数据增强\n",
        "def train_tf(x):\n",
        "    img_aug = tfs.Compose([\n",
        "        tfs.Resize(120),\n",
        "        tfs.RandomHorizontalFlip(),\n",
        "        tfs.RandomCrop(96),\n",
        "        tfs.ColorJitter(brightness = 0.5, contrast = 0.5, hue = 0.5),\n",
        "        tfs.ToTensor(),\n",
        "        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "    x = img_aug(x)\n",
        "    return x\n",
        "\n",
        "def test_tf(x):\n",
        "    img_aug = tfs.Compose([\n",
        "        tfs.Resize(96),\n",
        "        tfs.ToTensor(),\n",
        "        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    x = img_aug(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "train_set = CIFAR10('./data', train = True, transform = train_tf, download = True)\n",
        "test_set = CIFAR10('./data', train = False, transform = test_tf, download = True)\n",
        "\n",
        "train_data = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = 256)\n",
        "test_data = torch.utils.data.DataLoader(test_set, shuffle = False, batch_size = 256)\n",
        "\n",
        "net = resnet(3, 10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.1, weight_decay = 1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tkCS1lV3SsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter()\n",
        "\n",
        "def get_acc(output, label):\n",
        "    total = output.shape[0]\n",
        "    _, pred_label = output.max(1)\n",
        "    num_correct = (pred_label == label).sum().item()\n",
        "    return num_correct / total\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "\n",
        "prev_time = datetime.now()\n",
        "\n",
        "for epoch in range(30):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    net = net.train()\n",
        "    for im, label in train_data:\n",
        "        if torch.cuda.is_available():\n",
        "            im = Variable(im).cuda()\n",
        "            label = Variable(label).cuda()\n",
        "        else:\n",
        "            im = Variable(im)\n",
        "            label = Variable(label)\n",
        "        \n",
        "        output = net(im)\n",
        "        loss = criterion(output, label)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        train_acc += get_acc(output, label)\n",
        "    cur_time = datetime.now()\n",
        "    h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
        "    m, s = divmod(remainder, 60)\n",
        "    time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
        "    valid_loss = 0\n",
        "    valid_acc = 0\n",
        "    net = net.eval()\n",
        "    for im, label in test_data:\n",
        "        if torch.cuda.is_available():\n",
        "            im =Variable(im).cuda()\n",
        "            label =Variable(label).cuda()\n",
        "        else:\n",
        "            im = Variable(im)\n",
        "            lable = Variable(label)\n",
        "        \n",
        "        output = net(im)\n",
        "        loss = criterion(output, label)\n",
        "        valid_loss += loss.item()\n",
        "        valid_acc += get_acc(output, label)\n",
        "    epoch_str = \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f\" % (epoch, train_loss / len(train_data), train_acc / len(train_data), valid_loss / len(train_data), valid_acc / len(train_data))\n",
        "    prev_time = cur_time\n",
        "    writer.add_scalars('Loss', {'train': train_loss / len(train_data), 'valid': valid_loss / len(train_data)}, epoch)\n",
        "    writer.add_scalars('Acc', {'train': train_acc / len(train_data), 'valid': valid_acc / len(train_data)}, epoch)\n",
        "    print(epoch_str + time_str)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}